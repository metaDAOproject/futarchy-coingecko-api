# ===========================================
# Development Mode
# ===========================================
# Set to 'true' to disable external Dune API calls
# Useful for local development without hitting Dune rate limits
# When enabled, Dune services will return mock/empty data
# DEV_MODE=true

# Solana Configuration
SOLANA_RPC_URL=https://api.mainnet-beta.solana.com
SOLANA_WS_URL=wss://api.mainnet-beta.solana.com

DEX_FORK_TYPE="Uniswap V1"
FACTORY_ADDRESS=FUTARELBfJfQ8RDGhg1wdhddq1odMAJUePHFuBYfUxKq
ROUTER_ADDRESS=FUTARELBfJfQ8RDGhg1wdhddq1odMAJUePHFuBYfUxKq

# Server Configuration
PORT=3000
NODE_ENV=production
# Request timeout in milliseconds (default: 300000 = 5 minutes)
# SERVER_REQUEST_TIMEOUT=300000
# Keep-alive timeout in milliseconds (default: 300000 = 5 minutes)
# SERVER_KEEP_ALIVE_TIMEOUT=300000

# Blockchain Data Cache TTL in milliseconds (default: 10000 = 10 seconds)
# Controls how long pool data, prices, and other blockchain data is cached
# Lower = more real-time prices but more RPC calls
# Higher = less RPC load but slightly stale prices
# CACHE_TICKERS_TTL=10000

PROTOCOL_FEE_RATE=0.005

EXCLUDED_DAOS=DMB74TZgN7Rqfwtqqm3VQBgKBb2WYPdBqVtHbvB4LLeV,AE7jPb9jYzbUE5GYJToKvXaRkJL2Q7Mm3Ek6KqyBGuxe,E3BjsvLSFqUqVtDP76qMw4QbETkxvqvg8RTSbRZxWCK4,CnUUCGbSrAoaJniPifRU8zHRZ6e5uGRVSpCEj2WMeeSv,CLoqV77NtkbrsvtCRDP1vdYxgPZua3nnh7gCNPLzDQQ8,CJCgDqiDtkQvwXT2iiyY7QVajKLH3VRVbcsNQgtttrHn,651uV1hcd7SprwwkumFfkWtx5WrnD53awpjduGtGsHzS,4rW6iVKUq1RWYQ1VBTrjvP9FL4G3Sn7mBj7Yg12kuckv,Eo1BLMVRLJspjP5dDnwzK1m6FxMUcQDG6kDA8CjWPzRW,CTYxPujxrXiiqwG3gSBVNKuBk8u7mPG9qVMUc4aT1L8u,EbcsPbXZa81xUunDSmzYrcAWGURxcZB6BTkgzqvNJBZH,BgNq2V6vea2C7Z3cZhDUJTbmN4Y9bKG6dfEPhH19J7Fb,DHjQLd6LCM4yzZ9e8eabyGofDJLjbouqpuX8wh1rQuBs,BQjNtXjZB7b9WrqgJZQWfR52T1MqZoqMELAoombywDi8,j6Hx7bdAzcj1NsoRBqdafFuRkgEU48QeZ1i5NVXz9fF,AE7jPb9jYzbUE5GYJToKvXaRkJL2Q7Mm3Ek6KqyBGuxe

# Dune Analytics Configuration
# Get your API key from https://dune.com/settings/api
DUNE_API_KEY=your_dune_api_key_here

# 10-Minute volume query ID - PRIMARY query for rolling 24h metrics on /api/tickers
# This query should accept 'start_time', 'end_time', and 'token_list' parameters
# See src/schema/dune-ten-minute-volume.sql for the query template
# Runs every 10 minutes = 144 queries/day = ~4,320 queries/month
# Hourly and daily data are automatically aggregated from 10-minute data using DB functions
# DUNE_TEN_MINUTE_VOLUME_QUERY_ID=

# Meteora daily volumes query ID - tracks Meteora pool fees per owner
# This query should accept 'start_date' parameter
# See src/schema/dune-meteora-volumes.sql for the query template
# Runs once daily at 00:00 UTC (midnight) = 1 query/day = ~30 queries/month
# DUNE_METEORA_VOLUME_QUERY_ID=

# Dune Cache Configuration
# Cache refresh interval in seconds (default: 3600 = 1 hour)
# DUNE_CACHE_REFRESH_INTERVAL=3600
# Fetch timeout in seconds (default: 240 = 4 minutes)
# DUNE_FETCH_TIMEOUT=240

# Optional: Internal cache TTLs in seconds (used by DuneService internally)
# These are less important now that we have the main cache layer
# DUNE_CACHE_TTL=60
# DUNE_BATCH_CACHE_TTL=300
# DUNE_AGGREGATE_VOLUME_CACHE_TTL=600

# ===========================================
# PostgreSQL Database Configuration
# ===========================================
# Used for storing historical volume data to avoid re-fetching from Dune
# Either use DATABASE_URL or individual connection parameters

# Option 1: Connection string (recommended for cloud deployments)
# DATABASE_URL=postgresql://user:password@host:5432/database

# Option 2: Individual connection parameters
# DATABASE_HOST=localhost
# DATABASE_PORT=5432
# DATABASE_NAME=futarchy_volumes
# DATABASE_USER=postgres
# DATABASE_PASSWORD=
# DATABASE_SSL=false

# ===========================================
# Query Schedule (automatic, no config needed)
# ===========================================
# PRIMARY (10-min):  144 queries/day at :00, :10, :20, :30, :40, :50
#                    = ~4,320 queries/month
# This is the main source for /api/tickers 24h volume data
# Hourly and daily data are automatically aggregated from 10-minute data using DB functions